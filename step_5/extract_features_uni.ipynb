{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e260bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "#\n",
    "from numpy import log, mean, sqrt, where, std, exp, sign\n",
    "from scipy import linalg as LA\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "#\n",
    "from scipy.signal import savgol_filter\n",
    "#\n",
    "from scipy import stats\n",
    "from scipy.stats import entropy\n",
    "from scipy.stats import vonmises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308fafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import finfo\n",
    "epsilon = finfo(float).eps\n",
    "print(epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3f10d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# apply savgol_filter for records whose length is longer than window_length\n",
    "# if the record length is smaller than window_length, do not apply savgol_filter\n",
    "#\n",
    "def condition_length(x):\n",
    "    #\n",
    "    window_length = 25\n",
    "    poly_degree = 5\n",
    "    #\n",
    "    if (len(x) >= window_length):\n",
    "        return savgol_filter(x, window_length, poly_degree)\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db52e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# basic functions\n",
    "#\n",
    "def get_displacement(x_1, y_1, x_2, y_2):\n",
    "    # compute the displacement between two points\n",
    "    return sqrt((x_1-x_2)**2+(y_1-y_2)**2)\n",
    "\n",
    "def get_displacements(x, y):\n",
    "    #\n",
    "    # inputs\n",
    "    # x: list of x coordinate\n",
    "    # y: list of y coordinate\n",
    "    #\n",
    "    # results\n",
    "    # displacements: list of displacements between position at t(i-1) and t(i)\n",
    "    #\n",
    "    n_datapoints = len(x)\n",
    "    displacements = np.array([get_displacement(x[i-1], y[i-1], x[i], y[i]) for i in range(1, n_datapoints)])\n",
    "    return displacements\n",
    "\n",
    "def get_net_displacement(x, y):\n",
    "    n_datapoints = len(x)\n",
    "    x_0 = x[0]\n",
    "    y_0 = y[0]\n",
    "    x_f = x[n_datapoints-1]\n",
    "    y_f = y[n_datapoints-1]\n",
    "    net_displacement = get_displacement(x_0, y_0, x_f, y_f)\n",
    "    return net_displacement\n",
    "\n",
    "def get_d_traveled(x, y):\n",
    "    #\n",
    "    # inputs\n",
    "    # x: list of x coordinate\n",
    "    # y: list of y coordinate\n",
    "    #\n",
    "    # results\n",
    "    # d_traveled: sum of list of displacements\n",
    "    #    \n",
    "    n_datapoints = len(x)\n",
    "    d_traveled = sum(get_displacements(x, y)) \n",
    "    return d_traveled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b2ffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# feature 1: efficiency and straightness\n",
    "#\n",
    "def get_efficiency(x, y):\n",
    "    #\n",
    "    # inputs\n",
    "    # traj_x: list of x coordinate\n",
    "    # traj_y: list of y coordinate\n",
    "    #\n",
    "    # results\n",
    "    # efficiency: relevant to trajectory linearity; may be useful for detecting directed motion\n",
    "    #       \n",
    "    n_datapoints = len(x)\n",
    "    upper = get_displacement(x[n_datapoints-1], y[n_datapoints-1], x[0], y[0])**2\n",
    "    displacements_sq = get_displacements(x, y)**2\n",
    "    lower = (n_datapoints-1)*sum(displacements_sq)\n",
    "    efficiency = upper/lower\n",
    "    return efficiency\n",
    "\n",
    "def get_straightness(x, y):\n",
    "    #\n",
    "    # inputs\n",
    "    # x: list of x coordinate\n",
    "    # y: list of y coordinate\n",
    "    #\n",
    "    # results\n",
    "    # straightness: relevant to average direction change between subsequent steps; may be useful for detecting directed motion\n",
    "    #         \n",
    "    n_datapoints = len(x)\n",
    "    x_0 = x[0]\n",
    "    y_0 = y[0]\n",
    "    x_f = x[n_datapoints-1]\n",
    "    y_f = y[n_datapoints-1]     \n",
    "    upper = get_displacement(x_0, y_0, x_f, y_f)\n",
    "    lower = get_d_traveled(x, y)\n",
    "    straightness = upper/lower\n",
    "    return straightness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a70529",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# feature 2: turning angle \n",
    "#\n",
    "# entropy of turning angle \n",
    "# see:\n",
    "# Liu et al. PRE 2017\n",
    "# Establishing the kinetics of ballistic-to-diffusive transition using directional statistics\n",
    "# Appendix A: Determining theta from trajectory\n",
    "#\n",
    "def get_turning_angle_measures(traj_x, traj_y, tau_frame, binwidth):\n",
    "    #\n",
    "    # compute turning angle\n",
    "    #    \n",
    "    # traj_x = record_raw['relative_x']\n",
    "    # traj_y = record_raw['relative_y']\n",
    "    traj_x = pd.Series(traj_x)\n",
    "    traj_y = pd.Series(traj_y)\n",
    "    relative_x = traj_x[::tau_frame] # every tau-th row\n",
    "    relative_y = traj_y[::tau_frame] # every tau-th row  \n",
    "    relative_x = relative_x.reset_index(drop=True) # reset row index\n",
    "    relative_y = relative_y.reset_index(drop=True) # reset row index\n",
    "    turning_angle = []\n",
    "    for i in range (1, len(relative_x)-1):\n",
    "        # print(i)\n",
    "        diff_x1 = relative_x[i]-relative_x[i-1]\n",
    "        diff_x2 = relative_x[i+1]-relative_x[i]\n",
    "        diff_y1 = relative_y[i]-relative_y[i-1]\n",
    "        diff_y2 = relative_y[i+1]-relative_y[i] \n",
    "        # compute k1 and k2\n",
    "        k1 = 0 # diff_x1 > 0 and diff_y1 > 0\n",
    "        if (diff_x1 >= 0):\n",
    "            if (diff_y1 >= 0):\n",
    "                k1 = 0\n",
    "            else:\n",
    "                k1 = 2\n",
    "        if (diff_x1 < 0):\n",
    "            k1 = 1\n",
    "        k2 = 0\n",
    "        if (diff_x2 >= 0):\n",
    "            if (diff_y2 >= 0):\n",
    "                k2 = 0\n",
    "            else:\n",
    "                k2 = 2\n",
    "        if (diff_x2 < 0):\n",
    "            k2 = 1    \n",
    "        # compute phi_1 and phi_2\n",
    "        # arc tangent of y/x in radians\n",
    "        phi_1 = k1*np.pi + math.atan2(diff_y1, diff_x1) # 0, ..., 2*np.pi\n",
    "        phi_2 = k2*np.pi + math.atan2(diff_y2, diff_x2) # 0, ..., 2*np.pi\n",
    "        # compute m\n",
    "        m = 0\n",
    "        phi_diff = abs(phi_2-phi_1)\n",
    "        if (phi_diff < np.pi):\n",
    "            m = 0\n",
    "        if (phi_diff > np.pi):\n",
    "            if (phi_2 > phi_1):\n",
    "                m = -1\n",
    "            if (phi_2 < phi_1):\n",
    "                m = 1\n",
    "        # compute theta\n",
    "        theta_i = 2*m*np.pi+phi_2-phi_1  # -np.pi, ..., np.pi\n",
    "        turning_angle.append(theta_i)\n",
    "    #\n",
    "    # compute entropy\n",
    "    #\n",
    "    # epsilon_p = 0.0001\n",
    "    # epsilon_q = 0.0001\n",
    "    epsilon_p = epsilon\n",
    "    epsilon_q = epsilon \n",
    "    # create relative frequency histogram\n",
    "    turning_angle_deg = [(x/np.pi)*180.0 for x in turning_angle] # degree\n",
    "    x_max = 180 # deg\n",
    "    x_min = -180 # deg\n",
    "    #\n",
    "    bin_list = np.arange(x_min, x_max, binwidth) \n",
    "    hist_p, edges_p = np.histogram(turning_angle_deg, bins=bin_list)\n",
    "    freq_p = hist_p/float(hist_p.sum())\n",
    "    freq_p += epsilon_p\n",
    "    pk = np.reshape(freq_p, -1)\n",
    "    base = len(bin_list) # normalized entropy\n",
    "    entropy_p = entropy(pk, base=base)        \n",
    "    #\n",
    "    turning_angle_avg = np.mean(turning_angle)\n",
    "    turning_angle_std = np.std(turning_angle)\n",
    "    turning_angle_entropy = entropy_p\n",
    "    #\n",
    "    return turning_angle_avg, turning_angle_std, turning_angle_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eaeb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# feature 3: step size\n",
    "#\n",
    "def get_stepsize(traj_x, traj_y, tau_frame):\n",
    "    traj_x = pd.Series(traj_x)\n",
    "    traj_y = pd.Series(traj_y)\n",
    "    x_sampled = traj_x[::tau_frame] # every tau-th frames\n",
    "    y_sampled = traj_y[::tau_frame] # every tau-th frames\n",
    "    x_sampled = x_sampled.reset_index(drop=True) # reset index\n",
    "    y_sampled = y_sampled.reset_index(drop=True) # reset index\n",
    "    #\n",
    "    n_datapoints = len(x_sampled)\n",
    "    stepsize = np.array([get_displacement(x_sampled[i], y_sampled[i], x_sampled[i-1], y_sampled[i-1]) for i in range(1, n_datapoints)])\n",
    "    return stepsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8f83b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# additional information\n",
    "#\n",
    "def check_entering(x, y, r_contact):\n",
    "    N = len(x)\n",
    "    #\n",
    "    x_0 = x[0]\n",
    "    y_0 = y[0] \n",
    "    dij_0 = np.sqrt(x_0*x_0+y_0*y_0)\n",
    "    #\n",
    "    if (dij_0 >= (r_contact-0.05)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "#\n",
    "def check_exiting(x, y, r_contact):\n",
    "    N = len(x)\n",
    "    #\n",
    "    x_f = x[N-1]\n",
    "    y_f = y[N-1] \n",
    "    dij_f = np.sqrt(x_f*x_f+y_f*y_f)\n",
    "    #\n",
    "    if (dij_f >= (r_contact-0.05)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "#\n",
    "\n",
    "def estimate_von_mises(data):\n",
    "    res = vonmises.fit(data, fscale=1)\n",
    "    mu = res[1]\n",
    "    k = res[0]\n",
    "    return mu, k\n",
    "#\n",
    "\n",
    "def estimate_von_mises_mle(data):\n",
    "    #\n",
    "    # based on maximum likelihood estimation presented in Banerjee et al (2005) \n",
    "    # see:\n",
    "    # https://stats.stackexchange.com/questions/18692/estimating-kappa-of-von-mises-distribution\n",
    "    # https://stackoverflow.com/questions/47746500/estimating-parameters-of-von-mises-distribution-scipy-inconsistent-answers\n",
    "    #\n",
    "    dimension = 2\n",
    "    mu = np.arctan2(sum(np.sin(data)), sum(np.cos(data)))\n",
    "    A = sum(np.cos(data))*np.cos(mu)*(1/len(data))+ sum(np.sin(data))*np.sin(mu)*(1/len(data))\n",
    "    k = A*(dimension-A**2)/(1-A**2)\n",
    "    return mu, k\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8d6a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_motion_type(entropy, efficiency):\n",
    "    #\n",
    "    # threshold_values\n",
    "    # firstly, characterize ballistic motion by turning angle entropy H <= 0.26\n",
    "    # secondly, characterize confined motion by efficiency E <= 0.09\n",
    "    # lastly, characterize sub-ballistic motion for the parameter space does not belong to either ballistic or confined motions\n",
    "    #\n",
    "    entropy_threshold = 0.26\n",
    "    efficiency_threshold = 0.09\n",
    "    motion_type = \"\" \n",
    "    #\n",
    "    if (entropy <= entropy_threshold):\n",
    "        # ballistic motion\n",
    "        motion_type = \"B\"\n",
    "    else:\n",
    "        if (efficiency <= efficiency_threshold):\n",
    "            # confined motion\n",
    "            motion_type = \"C\"\n",
    "        else:\n",
    "            # sub-ballistic\n",
    "            motion_type = \"S\"            \n",
    "    #\n",
    "    return motion_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bda810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tc_assumed(r_contact, v_ini, angle_i, angle_j, angle_ij):\n",
    "    upper = 2*r_contact*abs(np.cos(angle_i)-np.cos(angle_j))\n",
    "    lower = v_ini*(1.0-np.cos(angle_ij))\n",
    "    if (lower <= epsilon):\n",
    "        lower = epsilon\n",
    "    tc_assumed = upper/lower\n",
    "    return tc_assumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e57733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(scenario_name, fps):\n",
    "    #\n",
    "    # t_temp = time.localtime()\n",
    "    # t_start = time.strftime(\"%H:%M:%S\", t_temp)\n",
    "    #\n",
    "    # read contact record\n",
    "    #\n",
    "    dt = 1.0/fps\n",
    "    readfile_name = \"contact_\"+str(fps)+\"fps_\"+scenario_name+\".txt\"\n",
    "    print (\"read \", readfile_name)\n",
    "    r_contact = 2.0\n",
    "    area_circle = np.pi*r_contact**2\n",
    "    #\n",
    "    columns = [\n",
    "    'frame', 'id_i', 'id_j', 'id_ij', 'degree_i', 'x_i', 'y_i', 'deltax_raw', 'deltay_raw', 'd_ij', \n",
    "    'angle_i', 'angle_j', 'angle_ij', 'v_i', 'v_j', 'v_ij', 'polarization']\n",
    "    #\n",
    "    record_raw = pd.read_csv(readfile_name, sep= \"\\t\", names = columns) \n",
    "    record_raw = record_raw.sort_values(['id_i', 'id_j', 'frame'], ascending=[True, True, True])\n",
    "    record_raw = record_raw.drop(record_raw[record_raw.d_ij > r_contact].index)\n",
    "    #\n",
    "    pairs_0 = record_raw['id_ij'].unique()\n",
    "    n_pairs0 = len(pairs_0)\n",
    "    #\n",
    "    record_groupby = record_raw.groupby(['id_ij'], group_keys=False, as_index=False).agg(list)\n",
    "    #\n",
    "    # remove id_ij recrods containing datapoints less than window_length\n",
    "    # https://stackoverflow.com/questions/37335598/how-to-get-the-length-of-a-cell-value-in-pandas-dataframe\n",
    "    #\n",
    "    # window_length_min is set as 10 based on literature\n",
    "    # Briane et al. (2016) An adaptive statistical test to detect non Brownian diffusion from particle trajectories\n",
    "    # Briane et al. (PRE 2018) Statistical analysis of particle trajectories in living cells\n",
    "    # \n",
    "    window_length = 25\n",
    "    window_length_min = 8\n",
    "    if (fps == 25):\n",
    "        window_length_min = 12  \n",
    "    record_groupby = record_groupby.drop(record_groupby[record_groupby.d_ij.str.len() < window_length_min].index)    \n",
    "    #\n",
    "    record_groupby['delta_x']=record_groupby['deltax_raw'].apply(condition_length)\n",
    "    record_groupby['delta_y']=record_groupby['deltay_raw'].apply(condition_length)\n",
    "    record_groupby = record_groupby.drop(columns=['id_i', 'id_j'])   \n",
    "    #\n",
    "    record_groupby = record_groupby.drop(['deltax_raw', 'deltay_raw'], axis=1)\n",
    "    record_groupby = record_groupby.drop(['x_i', 'y_i'], axis=1)\n",
    "    record_groupby = record_groupby.reindex(\n",
    "    columns=['id_ij', 'frame', 'degree_i', 'delta_x', 'delta_y', 'd_ij', 'angle_i', 'angle_j', 'angle_ij', 'v_i', 'v_j', 'v_ij'])\n",
    "    #\n",
    "    record_groupby['delta_x']=record_groupby['delta_x'].apply(lambda x: np.round(x, decimals=3))\n",
    "    record_groupby['delta_y']=record_groupby['delta_y'].apply(lambda x: np.round(x, decimals=3))\n",
    "    record_groupby['angle_i']=record_groupby['angle_i'].apply(lambda x: np.round(x, decimals=3))\n",
    "    record_groupby['angle_j']=record_groupby['angle_j'].apply(lambda x: np.round(x, decimals=3))\n",
    "    record_groupby['angle_ij']=record_groupby['angle_ij'].apply(lambda x: np.round(x, decimals=3))\n",
    "    record_groupby['v_i']=record_groupby['v_i'].apply(lambda x: np.round(x, decimals=3))\n",
    "    record_groupby['v_j']=record_groupby['v_j'].apply(lambda x: np.round(x, decimals=3))\n",
    "    record_groupby['v_ij']=record_groupby['v_ij'].apply(lambda x: np.round(x, decimals=3))    \n",
    "    #\n",
    "    pairs_1 = record_groupby['id_ij'].unique()\n",
    "    n_pairs1 = len(pairs_1)  \n",
    "    #\n",
    "    # create dataframe for summary\n",
    "    summary = pd.DataFrame(columns=[\n",
    "        'id_ij', \n",
    "        'frame_start',\n",
    "        'frame_end', \n",
    "        'n_datapoints',     \n",
    "        'heading_i',\n",
    "        'heading_iavg',\n",
    "        'heading_istd',\n",
    "        'heading_j',\n",
    "        'heading_javg',\n",
    "        'heading_jstd',\n",
    "        'alpha_ini',\n",
    "        'alpha_avg',\n",
    "        'alpha_std',         \n",
    "        'v_ini',\n",
    "        'v_avg',\n",
    "        'v_std',\n",
    "        'n_neighbors_avg', \n",
    "        'n_neighbors_std',\n",
    "        'entering_circle',\n",
    "        'exiting_cricle',\n",
    "        'tc_data',\n",
    "        'tc_assumed',         \n",
    "        'efficiency',\n",
    "        'net_displacement',\n",
    "        'd_traveled',        \n",
    "        'straightness',       \n",
    "        'turning_angle_avg',  \n",
    "        'turning_angle_std',  \n",
    "        'turning_angle_entropy',   \n",
    "        'stepsize_avg',\n",
    "        'stepsize_std',        \n",
    "        'motion_type'\n",
    "        ])\n",
    "    #\n",
    "    # compute features/metrics row by row\n",
    "    #\n",
    "    for index, row in record_groupby.iterrows():\n",
    "        #\n",
    "        frame = row['frame']\n",
    "        frame_start = row['frame'][0]          # contact interaction start time (frame)\n",
    "        frame_end = row['frame'][-1]           # contact interaction end time (frame)\n",
    "        relative_x = row['delta_x']\n",
    "        relative_y = row['delta_y']\n",
    "        relative_v = row['v_ij']\n",
    "        degree = row['degree_i']               # the number of neighbors within contact radius\n",
    "        #\n",
    "        angle_i = row['angle_i']\n",
    "        angle_j = row['angle_j']\n",
    "        angle_ij = row['angle_ij']             # contact angle between individuals in contact\n",
    "        #\n",
    "        heading_i = row['angle_i'][0]          # walking direction of individiual i at the beginning of contact interaction\n",
    "        heading_iavg = np.mean(row['angle_i'])\n",
    "        heading_istd = np.std(row['angle_i'])  \n",
    "        #\n",
    "        heading_j = row['angle_j'][0]          # walking direction of individiual j at the beginning of contact interaction\n",
    "        heading_javg = np.mean(row['angle_j'])\n",
    "        heading_jstd = np.std(row['angle_j'])          \n",
    "        #\n",
    "        alpha_ini = row['angle_ij'][0]          # contact angle at the beginning of contact interaction\n",
    "        alpha_avg = np.mean(row['angle_ij'])    # average of contact angle\n",
    "        alpha_std = np.std(row['angle_ij'])     # standard deviation of contact angle        \n",
    "        #\n",
    "        # basic values\n",
    "        #\n",
    "        # the number of trajectory data points \n",
    "        # represented the number of elements in x coordinate array/list\n",
    "        # in oother studies, this is denoted as \"total length of the path\" or \"trajectory length\"\n",
    "        n_datapoints = len(relative_x)\n",
    "        #\n",
    "        net_displacement = get_net_displacement(relative_x, relative_y)\n",
    "        # distance traveled within the contact radius\n",
    "        d_traveled = get_d_traveled(relative_x, relative_y)\n",
    "        #\n",
    "        # contact angle\n",
    "        alpha_ini = angle_ij[0]\n",
    "        #\n",
    "        # the number of neighbors\n",
    "        n_neighbors_avg = np.mean(degree)\n",
    "        n_neighbors_std = np.std(degree)\n",
    "        #\n",
    "        # feature 1: efficiency and straightness\n",
    "        #\n",
    "        efficiency = get_efficiency(relative_x, relative_y)\n",
    "        straightness = get_straightness(relative_x, relative_y)\n",
    "        #\n",
    "        # feature 2: turning angle\n",
    "        #\n",
    "        binwidth_turning_angle = 15 # deg\n",
    "        tau_turning_angle = 2 # frames (default 2)\n",
    "        if (fps == 25):\n",
    "            tau_turning_angle = 3 # frames (default 3)\n",
    "        #     \n",
    "        turning_angle_avg, turning_angle_std, turning_angle_entropy = get_turning_angle_measures(relative_x, relative_y, tau_turning_angle, binwidth_turning_angle)\n",
    "        #\n",
    "        # feature 3: step length\n",
    "        #\n",
    "        stepsize = get_stepsize(relative_x, relative_y, tau_turning_angle)\n",
    "        stepsize_avg = np.average(stepsize)\n",
    "        stepsize_std = np.std(stepsize)        \n",
    "        #\n",
    "        # von mises distribution parameter estimation\n",
    "        #\n",
    "        # mu_ij, k_ij = estimate_von_mises_mle(angle_ij) # estimate von mises distribution parameters        \n",
    "        #\n",
    "        # empirical contact duration and contact speed\n",
    "        #\n",
    "        tc_data = (n_datapoints-1)*dt # measured from experimental data \n",
    "        v_ini = relative_v[0]     \n",
    "        v_avg = np.mean(relative_v)\n",
    "        v_std = np.std(relative_v)\n",
    "        #\n",
    "        # motion type classification\n",
    "        #\n",
    "        motion_type_i = get_motion_type(turning_angle_entropy, efficiency)\n",
    "        #\n",
    "        # additional infomation\n",
    "        #\n",
    "        tc_assumed = get_tc_assumed(r_contact, v_ini, angle_i[0], angle_j[0], angle_ij[0]) # estimated based on ballistic motion assumption\n",
    "        entering_circle = check_entering(relative_x, relative_y, r_contact)\n",
    "        exiting_circle = check_exiting(relative_x, relative_y, r_contact) \n",
    "        #\n",
    "        # append records row by row\n",
    "        # \n",
    "        summary.loc[index] = pd.Series({           \n",
    "            'id_ij': row['id_ij'], \n",
    "            'frame_start': int(frame_start),\n",
    "            'frame_end': int(frame_end), \n",
    "            'n_datapoints': n_datapoints,           \n",
    "            'heading_i': round(heading_i, 3),\n",
    "            'heading_iavg': round(heading_iavg, 3),\n",
    "            'heading_istd': round(heading_istd, 3),\n",
    "            'heading_j': round(heading_j, 3),\n",
    "            'heading_javg': round(heading_javg, 3),\n",
    "            'heading_jstd': round(heading_jstd, 3),\n",
    "            'alpha_ini': round(alpha_ini, 3),\n",
    "            'alpha_avg': round(alpha_avg, 3),\n",
    "            'alpha_std': round(alpha_std, 3),               \n",
    "            'v_ini': v_ini.round(3), \n",
    "            'v_avg': v_avg.round(3), \n",
    "            'v_std': v_std.round(3),\n",
    "            'n_neighbors_avg': round(n_neighbors_avg, 2), \n",
    "            'n_neighbors_std': round(n_neighbors_std, 2),              \n",
    "            'entering_circle': int(entering_circle),\n",
    "            'exiting_cricle': int(exiting_circle),   \n",
    "            'tc_data': round(tc_data, 3),  \n",
    "            'tc_assumed': round(tc_assumed, 3),              \n",
    "            'efficiency': efficiency.round(3),  \n",
    "            'net_displacement': net_displacement.round(3),\n",
    "            'd_traveled': round(d_traveled, 3),            \n",
    "            'straightness': straightness.round(3),\n",
    "            'turning_angle_avg': round(turning_angle_avg, 3),    \n",
    "            'turning_angle_std': round(turning_angle_std, 3),  \n",
    "            'turning_angle_entropy': round(turning_angle_entropy, 3),\n",
    "            'stepsize_avg': round(stepsize_avg, 3),\n",
    "            'stepsize_std': round(stepsize_std, 3),              \n",
    "            'motion_type': motion_type_i,\n",
    "        })\n",
    "    #\n",
    "    # sort dataframe by contact interaction end and start frames\n",
    "    #\n",
    "    summary.sort_values(by=['frame_end', 'frame_start'])         \n",
    "    #\n",
    "    # write features for classification inputs\n",
    "    #\n",
    "    filename_write = 'traj-classification-features_'+scenario_name+'.txt'\n",
    "    summary.to_csv(filename_write, index=False)   \n",
    "    #\n",
    "    # print statistics\n",
    "    #\n",
    "    print(str(n_pairs0)+\"\\t\"+str(n_pairs1))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b749ee34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scenario_name_set = [\"uni-01\", \"uni-02\", \"uni-03\", \"uni-04\", \"uni-05\", \n",
    "                     \"uni-06\", \"uni-07\", \"uni-08\", \"uni-09\"]\n",
    "#\n",
    "fps_values = [25]\n",
    "#\n",
    "for i in range(0, len(scenario_name_set)):\n",
    "    t_temp = time.localtime()\n",
    "    t_start = time.strftime(\"%H:%M:%S\", t_temp)\n",
    "    print(t_start)\n",
    "    #\n",
    "    # print(scenario_name_set[i], fps_values[i])\n",
    "    extract_features(scenario_name_set[i], fps_values[0])\n",
    "    #\n",
    "    t_temp = time.localtime()\n",
    "    t_end = time.strftime(\"%H:%M:%S\", t_temp)\n",
    "    print(t_end)    \n",
    "    print(t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2f3a37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
